{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObee3aeXItBAZgqsyDzNQu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BPE (Byte Pair Encoding)**"
      ],
      "metadata": {
        "id": "3Brr-F1_LI9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Words are broken into small tokens that are more repeating and base of other word.\n",
        "For exmaple: Token , Tokens , Tokenization are similar"
      ],
      "metadata": {
        "id": "MbeQTBb1N_pF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Wikipedia example\n",
        "\n",
        "Suppose the data to be encoded is\n",
        "\n",
        "**aaabdaaabac**\n",
        "\n",
        "The byte pair **\"aa\"** occurs most often, so it will be replaced by a byte that is not used in the data, such as **\"Z\"**. Now there is the following data and replacement table:\n",
        "\n",
        "**ZabdZabac**\n",
        "\n",
        "**Z=aa**\n",
        "\n",
        "Then the process is repeated with byte pair **\"ab\"**, replacing it with **\"Y\"**:\n",
        "\n",
        "**ZYdZYac**\n",
        "\n",
        "**Y=ab**\n",
        "\n",
        "**Z=aa**\n",
        "\n",
        "The only literal byte pair left occurs only once, and the encoding might stop here. Alternatively, the process could continue with recursive byte pair encoding, replacing \"ZY\" with \"X\":\n",
        "\n",
        "**XdXac**\n",
        "\n",
        "**X=ZY**\n",
        "\n",
        "**Y=ab**\n",
        "\n",
        "**Z=aa**\n",
        "\n",
        "This data cannot be compressed further by byte pair encoding because there are no pairs of bytes that occur more than once.\n",
        "\n",
        "To decompress the data, simply perform the replacements in the reverse order."
      ],
      "metadata": {
        "id": "bet7JcNuOxPv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXNPkKddK4Kw",
        "outputId": "9f34d797-2fb5-413f-8699-d968c982a968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "! pip3 install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing libraries"
      ],
      "metadata": {
        "id": "mCXvgqz8MrP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "\n",
        "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmU1bFTILtXh",
        "outputId": "6ccbae34-fb7c-4555-9d02-0db85979d25c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using gpt2 tokenizer"
      ],
      "metadata": {
        "id": "SHtMsWlBMmHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\") #BPE"
      ],
      "metadata": {
        "id": "3iI41ya0Mc4d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example"
      ],
      "metadata": {
        "id": "g2fIMGXeMjQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        "     \"of someunknownPlace.\"\n",
        ")\n",
        "\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"}) # encode method\n",
        "\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dkAl99tMehD",
        "outputId": "bb38e1a8-8b8b-4838-dd3d-07b0713da443"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers) # decode method\n",
        "\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR_mXTDPMiXn",
        "outputId": "1f1d45e2-3bd1-4d2a-c131-a7010a96d365"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "integers = tokenizer.encode(\"abracadabra hafshfk\") # unknown text\n",
        "print(integers)\n",
        "\n",
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnCNcID3MxL8",
        "outputId": "0b7bb3bc-2a46-4a68-94f7-3dc1414592fd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[397, 11510, 324, 397, 430, 387, 69, 1477, 69, 74]\n",
            "abracadabra hafshfk\n"
          ]
        }
      ]
    }
  ]
}
